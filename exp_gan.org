#+TITLE:
#+AUTHOR: Ant√≥nio Mendes
#+DATE: 06 / 12 / 20
#+email: 17amendes@gmail.com
#+PROPERTY: header-args :exports both :session _watermark :results value
#+OPTIONS: toc:nil num:nil
#+LaTeX_HEADER: \usepackage[left=3.5cm, top=2.5cm, right=3.5cm, includefoot]{geometry}
-----

* Imports
** standard
#+BEGIN_SRC python
import numpy  as np
import pandas as pd
import cv2 
from pexels_api import API 
#+END_SRC

#+RESULTS:

** matplotlib
#+BEGIN_SRC python
import matplotlib.pyplot as plt
plt.style.use("fivethirtyeight")
import matplotlib.ticker as ticker

plt.rcParams["font.family"] = "Times New Roman"

from mpl_toolkits.mplot3d import Axes3D
#+END_SRC

#+RESULTS:

** import os and getting current directory
#+BEGIN_SRC python :results file
import os 
from pathlib import Path
cwd = os.path.abspath(os.getcwd())
cwd
#+END_SRC

#+RESULTS:
[[file:/Users/antoniomendes/Desktop/uva_data_science/semester_01/block_02/AML/Kaggle_Project]]

*** =fig_dir=
#+BEGIN_SRC python :results file
fig_dir = Path("/".join(cwd.split("/"))) / "figures"
if fig_dir.exists() == False:
  os.mkdir(fig_dir)

fig_dir
#+END_SRC

#+RESULTS:
[[file:/Users/antoniomendes/Desktop/uva_data_science/semester_01/block_02/AML/Kaggle_Project/figures]]

*** =data_dir=
#+BEGIN_SRC python :results file
data_dir = Path("/".join(cwd.split("/"))) / "data"
if data_dir.exists() == False:
  os.mkdir(data_dir)

data_dir
#+END_SRC

#+RESULTS:
[[file:/Users/antoniomendes/Desktop/uva_data_science/semester_01/block_02/AML/Kaggle_Project/data]]

**** =pexel_img_dir=
#+BEGIN_SRC python :results file
pexel_img_dir = data_dir / "pexel_img_dir" 
if pexel_img_dir.exists() == False:
  os.mkdir(pexel_img_dir)

pexel_img_dir
#+END_SRC

#+RESULTS:
[[file:/Users/antoniomendes/Desktop/uva_data_science/semester_01/block_02/AML/Kaggle_Project/data/pexel_img_dir]]

**** =watermark_pexel_img_dir=
#+BEGIN_SRC python :results file
watermark_pexel_img_dir = data_dir / "watermark_pexel_img_dir"
if watermark_pexel_img_dir.exists() == False:
  os.mkdir(watermark_pexel_img_dir)

watermark_pexel_img_dir
#+END_SRC

#+RESULTS:
[[file:/Users/antoniomendes/Desktop/uva_data_science/semester_01/block_02/AML/Kaggle_Project/data/watermark_pexel_img_dir]]

**** =font_dir=
#+BEGIN_SRC python :results file
font_dir = data_dir / "fonts"
if font_dir.exists() == False:
  os.mkdir(font_dir)

font_dir
#+END_SRC

#+RESULTS:
[[file:/Users/antoniomendes/Desktop/uva_data_science/semester_01/block_02/AML/Kaggle_Project/data/fonts]]

*** =model_dir=
#+BEGIN_SRC python :results file
model_dir = Path(cwd) / "models"
if model_dir.exists() == False:
  os.mkdir(model_dir)

model_dir
#+END_SRC

#+RESULTS:
[[file:/Users/antoniomendes/Desktop/uva_data_science/semester_01/block_02/AML/Kaggle_Project/models]]

** tools
#+BEGIN_SRC python
import PIL
import requests
import shutil
import string
import time

from tqdm import tqdm

from PIL import Image
from PIL import ImageDraw
from PIL import ImageFont


from IPython.display import clear_output
#+END_SRC

#+RESULTS:

** tensorflow
#+BEGIN_SRC python
import tensorflow as tf

from tensorflow.keras import layers
from keras.models import Sequential, Model, load_model
from tensorflow.keras.preprocessing.image import ImageDataGenerator

import tensorflow_datasets as tfds

from tensorflow_examples.models.pix2pix import pix2pix
#+END_SRC

#+RESULTS:

** keras
#+BEGIN_SRC python
from keras.datasets.cifar10 import load_data
#+END_SRC

#+RESULTS:

** fastai
#+BEGIN_SRC python
import fastai


from fastai.vision import *
#+END_SRC

#+RESULTS:

* Data
** Load Pexel Images
*** =search_terms=
#+BEGIN_SRC python
search_terms = [
  "kitten",
  "dog",
  "food",
  "cake",
  "pasta",
  "people",
  "steak",
  "cooked chicken",
  "chicken wings",
  "crab food",
  "seafood",
  "oyster",
  "donut",
  "burger",
  "pizza",
  "egg",
  "avocado",
  "bread",
  "salad",
  "sandwich",
  "fries",
  "butter",
  "ham",
  "sausage",
  "bacon",
  "dessert",
  "rice",
  "lasagna",
  "green peas",
]
#+END_SRC

#+RESULTS:

*** Scrape the Images
**** Folders for Each Search Term
#+BEGIN_SRC python
PEXELS_API_KEY = "563492ad6f91700001000001f8f1cdfad4e84affa3d8bb8ea5312020"

api = API(PEXELS_API_KEY)

for i, search_term in enumerate(tqdm(search_terms)):
  print("search_term: ", search_term)
  search = api.search(search_term, page=1, results_per_page=40)
  photos = api.get_entries()
  folder_name = "_".join(search_term.split(" "))
  folder_dir = pexel_img_dir / folder_name
  if folder_dir.exists() == False: 
    os.mkdir(folder_dir)
  for j,photo in enumerate(photos):
    #img_url = photo.compressed
    #img_url = photo.large
    img_url = photo.medium
    filename = str(search_term + "_" + str(j) + ".jpg")
    r = requests.get(img_url, stream=True)
    if r.status_code == 200:
      with open(folder_dir / filename, 'wb') as f:
        r.raw.decode_content = True
        shutil.copyfileobj(r.raw, f)
#+END_SRC

#+RESULTS:
: 3

**** One Folder for all Search Terms
#+BEGIN_SRC python
pexel_folder_dir = pexel_img_dir / "pexel_images"
if pexel_folder_dir.exists() == False:
  os.mkdir(pexel_folder_dir)

PEXELS_API_KEY = "563492ad6f91700001000001f8f1cdfad4e84affa3d8bb8ea5312020"

api = API(PEXELS_API_KEY)

for i, search_term in enumerate(tqdm(search_terms)):
  print("search_term: ", search_term)
  search = api.search(search_term, page=1, results_per_page=40)
  photos = api.get_entries()
  if folder_dir.exists() == False: 
    os.mkdir(folder_dir)
  for j,photo in enumerate(photos):
    #img_url = photo.compressed
    #img_url = photo.large
    img_url = photo.medium
    filename = str(search_term + "_" + str(j) + ".jpg")
    r = requests.get(img_url, stream=True)
    if r.status_code == 200:
      with open(pexel_folder_dir / filename, 'wb') as f:
        r.raw.decode_content = True
        shutil.copyfileobj(r.raw, f)
#+END_SRC

** Watermark Pexel Images
*** [[https://rickwierenga.com/blog/machine%20learning/GanWatermark.html][Crappifying Images]]
**** Folders for Each Search Term
#+BEGIN_SRC python :results file
fonts = os.listdir(font_dir)
if ".DS_Store" in fonts:
  fonts.remove(".DS_Store")

for folder_name in tqdm(os.listdir(pexel_img_dir)):
  folder_dir = pexel_img_dir / folder_name
  folder_images = os.listdir(folder_dir)
  if ".DS_Store" in folder_images:
    folder_images.remove(".DS_Store")
  for im in folder_images:
    img = Image.open(folder_dir / im).convert("RGB")
    width, height, _ = np.array(img).shape
    font_multiplier = 1 if width * height <= 1000**2 else round(width * height/1000**2)
    d = PIL.ImageDraw.Draw(img)
    #print("font_multiplier: ", font_multiplier)
    for i in range(np.random.randint(5, 50)):
      font_file = np.random.choice(fonts)
      fnt = PIL.ImageFont.truetype(str(font_dir / font_file), size=np.random.randint(20, 40))
      fnt.size = np.random.randint(40, 125)
      font_width = np.random.random() * width #* font_multiplier
      font_height = np.random.random() * height #* font_multiplier
      d.text((font_width, font_height), ''.join([np.random.choice(list(string.digits + string.ascii_letters)) for x in range(20)]), fill=(np.random.randint(0,255), np.random.randint(0,255), np.random.randint(0,255)), font=fnt)
    watermark_folder_dir = watermark_pexel_img_dir / folder_name
    if watermark_folder_dir.exists() == False: 
      os.mkdir(watermark_folder_dir)
    img.save(watermark_folder_dir / str("watermark_" + im))
    curr_dir = watermark_folder_dir / str("watermark_" + im)

curr_dir
#+END_SRC

#+RESULTS:

**** One Folder for all Search Terms
#+BEGIN_SRC python :results file
fonts = os.listdir(font_dir)
if ".DS_Store" in fonts:
  fonts.remove(".DS_Store")

pexel_folder_dir = pexel_img_dir / "pexel_images"
pexel_images = os.listdir(pexel_folder_dir)
if ".DS_Store" in pexel_images:
  pexel_images.remove(".DS_Store")

watermark_folder_dir = watermark_pexel_img_dir / "watermark_pexel_images"
if watermark_folder_dir.exists() == False:
  os.mkdir(watermark_folder_dir)

curr_dir = None

for im in tqdm(pexel_images):
  img = Image.open(pexel_img_dir / im).convert("RGB")
  width, height, _ = np.array(img).shape
  font_multiplier = 1 if width * height <= 1000**2 else round(width * height/1000**2)
  d = PIL.ImageDraw.Draw(img)
  #print("font_multiplier: ", font_multiplier)
  for i in range(np.random.randint(5, 50)):
    font_file = np.random.choice(fonts)
    fnt = PIL.ImageFont.truetype(str(font_dir / font_file), size=np.random.randint(20, 40))
    fnt.size = np.random.randint(40, 125)
    font_width = np.random.random() * width #* font_multiplier
    font_height = np.random.random() * height #* font_multiplier
    d.text((font_width, font_height), ''.join([np.random.choice(list(string.digits + string.ascii_letters)) for x in range(20)]), fill=(np.random.randint(0,255), np.random.randint(0,255), np.random.randint(0,255)), font=fnt)
  img.save(watermark_pexel_img_dir / str("watermark_" + im))
  curr_dir = watermark_folder_img_dir / str("watermark_" + im)

curr_dir
#+END_SRC

#+RESULTS:
[[file:3]]

** Make =watermark_df= 
#+BEGIN_SRC python 
pexel_images = os.listdir(pexel_img_dir)
if ".DS_Store" in pexel_images:
  pexel_images.remove(".DS_Store")

wm_pexel_images = os.listdir(watermark_pexel_img_dir)
if ".DS_Store" in wm_pexel_images:
  wm_pexel_images.remove(".DS_Store")

watermark_df = pd.DataFrame({
  "image_name" : np.append(pexel_images, wm_pexel_images),
  "has_watermark" : np.append(np.zeros(len(pexel_images)), np.ones(len(wm_pexel_images))).astype(int)
})

watermark_df.shape
#+END_SRC

#+RESULTS:
| 2 | 2 |

*** Save =watermark_df=
#+BEGIN_SRC python
watermark_df.to_csv(data_dir / "watermark_df.csv")
#+END_SRC

#+RESULTS:
: 3

* cycleGAN
** Data
*** Normal
**** train
#+BEGIN_SRC python
batch_size = 1
img_height = 256
img_width = 256

train_normal = tf.keras.preprocessing.image_dataset_from_directory(
  pexel_img_dir,
  validation_split=0.2,
  subset="training",
  color_mode="rgb",
  seed=123,
  image_size=(img_height, img_width),
  batch_size=batch_size
)

train_normal
#+END_SRC

#+RESULTS:
: <BatchDataset shapes: ((None, 256, 256, 3), (None,)), types: (tf.float32, tf.int32)>

**** test
#+BEGIN_SRC python
batch_size = 1
img_height = 256
img_width = 256

test_normal = tf.keras.preprocessing.image_dataset_from_directory(
  pexel_img_dir,
  validation_split=0.2,
  subset="validation",
  color_mode="rgb",
  seed=123,
  image_size=(img_height, img_width),
  batch_size=batch_size
)

test_normal
#+END_SRC

#+RESULTS:
: <BatchDataset shapes: ((None, 256, 256, 3), (None,)), types: (tf.float32, tf.int32)>
*** Watermarked
**** train
#+BEGIN_SRC python
batch_size = 1
img_height = 256
img_width = 256

train_watermark = tf.keras.preprocessing.image_dataset_from_directory(
  watermark_pexel_img_dir,
  validation_split=0.2,
  subset="training",
  color_mode="rgb",
  seed=123,
  image_size=(img_height, img_width),
  batch_size=batch_size
)

train_watermark
#+END_SRC

#+RESULTS:
: <BatchDataset shapes: ((None, 256, 256, 3), (None,)), types: (tf.float32, tf.int32)>

**** test
#+BEGIN_SRC python
batch_size = 1
img_height = 256
img_width = 256

test_watermark = tf.keras.preprocessing.image_dataset_from_directory(
  watermark_pexel_img_dir,
  validation_split=0.2,
  subset="validation",
  color_mode="rgb",
  seed=123,
  image_size=(img_height, img_width),
  batch_size=batch_size
)

test_watermark
#+END_SRC

#+RESULTS:
: <BatchDataset shapes: ((None, 256, 256, 3), (None,)), types: (tf.float32, tf.int32)>

*** Preprocess Data
**** Preprocess Functions
#+BEGIN_SRC python
def normalize(image):
  image = tf.cast(image, tf.float32)
  image = (image / 127.5) - 1
  return image

def preprocess_image_train(image, label):
  #image = random_jitter(image)
  image = normalize(image)
  return image

def preprocess_image_test(image, label):
  image = normalize(image)
  return image
#+END_SRC

#+RESULTS:

**** Preprocess Normal Data
#+BEGIN_SRC python
AUTOTUNE = tf.data.experimental.AUTOTUNE
BUFFER_SIZE = 1000

train_normal = train_normal.map(
  preprocess_image_train,
  num_parallel_calls=AUTOTUNE
).cache().shuffle(BUFFER_SIZE).batch(1)

test_normal = test_normal.map(
  preprocess_image_test, 
  num_parallel_calls=AUTOTUNE
).cache().shuffle(BUFFER_SIZE).batch(1)
#+END_SRC

#+RESULTS:

**** Preprocess Watermark Data
#+BEGIN_SRC python
AUTOTUNE = tf.data.experimental.AUTOTUNE
BUFFER_SIZE = 1000

train_watermark = train_watermark.map(
  preprocess_image_train, 
  num_parallel_calls=AUTOTUNE
).cache().shuffle(BUFFER_SIZE).batch(1)

test_watermark = test_watermark.map(
  preprocess_image_test, 
  num_parallel_calls=AUTOTUNE
).cache().shuffle(BUFFER_SIZE).batch(1)
#+END_SRC

#+RESULTS:

**** View New Data
#+BEGIN_SRC python
for image_x, image_y in tqdm(tf.data.Dataset.zip((train_normal, train_watermark))):
  #print(image_x)
  print("len(image_x): ", len(image_x))
  print("len(image_x[0]): ", len(image_x[0]))
  print("image_x[0][0].shape: ",image_x[0][0].shape)
  print(image_x)
  break
#+END_SRC

#+RESULTS:

#+BEGIN_SRC python
for image_x, image_y in tqdm(tf.data.Dataset.zip((test_normal, test_watermark))):
  print("len(image_x): ", len(image_x))
  print("len(image_x[0]): ", len(image_x[0]))
  print("image_x[0][0].shape: ",image_x[0][0].shape)
  print(image_x)
  break
#+END_SRC

*** sample_datasets 
#+BEGIN_SRC python
sample_normal = next(iter(train_normal))
sample_watermark = next(iter(train_watermark))
#+END_SRC

#+RESULTS:

** Models
*** generators
#+BEGIN_SRC python
OUTPUT_CHANNELS = 3

generator_g = pix2pix.unet_generator(OUTPUT_CHANNELS, norm_type='instancenorm')
generator_f = pix2pix.unet_generator(OUTPUT_CHANNELS, norm_type='instancenorm')
#+END_SRC

#+RESULTS:

*** discriminators
#+BEGIN_SRC python
discriminator_x = pix2pix.discriminator(norm_type='instancenorm', target=False)
discriminator_y = pix2pix.discriminator(norm_type='instancenorm', target=False)
#+END_SRC

#+RESULTS:

*** OR LOAD MODELS
#+BEGIN_SRC python
generator_g = tf.keras.models.load_model(model_dir / "generator_g")
generator_f = tf.keras.models.load_model(model_dir / "generator_f")

discriminator_x = tf.keras.models.load_model(model_dir / "discriminator_x")
discriminator_y = tf.keras.models.load_model(model_dir / "discriminator_y")
#generate_images(other_model, sample_watermark[0])
#+END_SRC

#+RESULTS:

** Loss Functions
*** generator and discriminator loss
#+BEGIN_SRC python
loss_obj = tf.keras.losses.BinaryCrossentropy(from_logits=True)

def discriminator_loss(real, generated):
  real_loss = loss_obj(tf.ones_like(real), real)
  generated_loss = loss_obj(tf.zeros_like(generated), generated)
  total_disc_loss = real_loss + generated_loss
  return total_disc_loss * 0.5


def generator_loss(generated):
  return loss_obj(tf.ones_like(generated), generated)
#+END_SRC

#+RESULTS:

*** calc_cycle_loss
#+BEGIN_SRC python
LAMBDA = 10

def calc_cycle_loss(real_image, cycled_image):
  loss1 = tf.reduce_mean(tf.abs(real_image - cycled_image))
  return LAMBDA * loss1
#+END_SRC

#+RESULTS:

*** identity_loss
#+BEGIN_SRC python
LAMBDA = 10

def identity_loss(real_image, same_image):
  loss = tf.reduce_mean(tf.abs(real_image - same_image))
  return LAMBDA * 0.5 * loss
#+END_SRC

#+RESULTS:

** Optimisers
#+BEGIN_SRC python
generator_g_optimizer = tf.keras.optimizers.Adam(2e-4, beta_1=0.5)
generator_f_optimizer = tf.keras.optimizers.Adam(2e-4, beta_1=0.5)

discriminator_x_optimizer = tf.keras.optimizers.Adam(2e-4, beta_1=0.5)
discriminator_y_optimizer = tf.keras.optimizers.Adam(2e-4, beta_1=0.5)
#+END_SRC

#+RESULTS:

** Checkpoints 
#+BEGIN_SRC python
checkpoint_path = "./checkpoints/train"

ckpt = tf.train.Checkpoint(generator_g=generator_g,
                           generator_f=generator_f,
                           discriminator_x=discriminator_x,
                           discriminator_y=discriminator_y,
                           generator_g_optimizer=generator_g_optimizer,
                           generator_f_optimizer=generator_f_optimizer,
                           discriminator_x_optimizer=discriminator_x_optimizer,
                           discriminator_y_optimizer=discriminator_y_optimizer)

ckpt_manager = tf.train.CheckpointManager(ckpt, checkpoint_path, max_to_keep=5)

# if a checkpoint exists, restore the latest checkpoint.
if ckpt_manager.latest_checkpoint:
  ckpt.restore(ckpt_manager.latest_checkpoint)
  print ('Latest checkpoint restored!!')
#+END_SRC

#+RESULTS:
: <tensorflow.python.training.tracking.util.CheckpointLoadStatus object at 0x270848f60>
** Training
*** =generate_images()=
#+BEGIN_SRC python
def generate_images(model, test_input):
  prediction = model(test_input)
  plt.figure(figsize=(12, 12))
  display_list = [test_input[0], prediction[0]]
  title = ['Input Image', 'Predicted Image']
  fig, ax = plt.subplots(1, 2, sharex=True, sharey=True, figsize=(60, 46))
  plt.subplots_adjust(wspace=0.3)
  for i in range(2):
    #print("display_list[i][0,:]: ", display_list[i][0,:])
    #print("title[i]: ", title[i])
    ax[i].imshow(display_list[i] * 0.5 + 0.5) 
    ax[i].set_title(title[i])
    ax[i].axis('off')
  plt.savefig(fig_dir / "curr_removal.png", bbox_inches="tight")
#+END_SRC

#+RESULTS:

*** =train_step()=
#+BEGIN_SRC python
@tf.function
def train_step(real_x, real_y):
  # persistent is set to True because the tape is used more than
  # once to calculate the gradients.
  with tf.GradientTape(persistent=True) as tape:
    # Generator G translates X -> Y
    # Generator F translates Y -> X.
    #
    fake_y = generator_g(real_x, training=True)
    cycled_x = generator_f(fake_y, training=True)
    #
    fake_x = generator_f(real_y, training=True)
    cycled_y = generator_g(fake_x, training=True)
    #
    # same_x and same_y are used for identity loss.
    same_x = generator_f(real_x, training=True)
    same_y = generator_g(real_y, training=True)
    #
    disc_real_x = discriminator_x(real_x, training=True)
    disc_real_y = discriminator_y(real_y, training=True)
    #
    disc_fake_x = discriminator_x(fake_x, training=True)
    disc_fake_y = discriminator_y(fake_y, training=True)
    #
    # calculate the loss
    gen_g_loss = generator_loss(disc_fake_y)
    gen_f_loss = generator_loss(disc_fake_x)
    #
    total_cycle_loss = calc_cycle_loss(real_x, cycled_x) + calc_cycle_loss(real_y, cycled_y)
    #
    # Total generator loss = adversarial loss + cycle loss
    total_gen_g_loss = gen_g_loss + total_cycle_loss + identity_loss(real_y, same_y)
    total_gen_f_loss = gen_f_loss + total_cycle_loss + identity_loss(real_x, same_x)
    #
    disc_x_loss = discriminator_loss(disc_real_x, disc_fake_x)
    disc_y_loss = discriminator_loss(disc_real_y, disc_fake_y)
  # Calculate the gradients for generator and discriminator
  generator_g_gradients = tape.gradient(total_gen_g_loss, generator_g.trainable_variables)
  generator_f_gradients = tape.gradient(total_gen_f_loss, generator_f.trainable_variables)
  #
  discriminator_x_gradients = tape.gradient(disc_x_loss, discriminator_x.trainable_variables)
  discriminator_y_gradients = tape.gradient(disc_y_loss, discriminator_y.trainable_variables)
  #
  # Apply the gradients to the optimizer
  generator_g_optimizer.apply_gradients(zip(generator_g_gradients, generator_g.trainable_variables))
  #
  generator_f_optimizer.apply_gradients(zip(generator_f_gradients, generator_f.trainable_variables))
  #
  discriminator_x_optimizer.apply_gradients(zip(discriminator_x_gradients,discriminator_x.trainable_variables))
  #
  discriminator_y_optimizer.apply_gradients(zip(discriminator_y_gradients,discriminator_y.trainable_variables))
#+END_SRC

#+RESULTS:
*** Train the Models
#+BEGIN_SRC python
EPOCHS = 15

for epoch in tqdm(range(25, EPOCHS+25)):
  start = time.time()
  #
  n = 0
  for image_x, image_y in tf.data.Dataset.zip((train_normal, train_watermark)):
    train_step(image_x[0], image_y[0])
    #train_step(image_x, image_y)
    if n % 10 == 0:
      print ('.', end='')
    n+=1
    #break
    #
  clear_output(wait=True)
  # Using a consistent image (sample_horse) so that the progress of the model
  # is clearly visible.
  #generate_images(generator_g, sample_normal[0])
  generate_images(generator_f, sample_watermark[0])
  #
  if (epoch + 1) % 5 == 0:
    ckpt_save_path = ckpt_manager.save()
    print ('Saving checkpoint for epoch {} at {}'.format(epoch+1, ckpt_save_path))
    #
  print ('Time taken for epoch {} is {} sec\n'.format(epoch + 1, time.time()-start))
  
#+END_SRC

#+RESULTS:

*** View Data
#+BEGIN_SRC python
for image_x, image_y in tqdm(tf.data.Dataset.zip((train_normal, train_watermark))):
  #print(image_x)
  print("len(image_x): ", len(image_x))
  print("len(image_x[0]): ", len(image_x[0]))
  print("image_x[0][0].shape: ",image_x[0][0].shape)
  print(image_x)
  break
#+END_SRC

#+RESULTS:


#+BEGIN_SRC python
for image_x, image_y in tqdm(tf.data.Dataset.zip((test_normal, test_watermark))):
  #print(image_x)
  print("len(image_x): ", len(image_x))
  print("len(image_x[0]): ", len(image_x[0]))
  print("image_x[0][0].shape: ",image_x[0][0].shape)
  print(image_x)
  break
#+END_SRC

#+RESULTS:

#+BEGIN_SRC python
for image_x, image_y in tqdm(tf.data.Dataset.zip((train_horses, train_zebras))):
  #print(image_x)
  print("len(image_x): ", len(image_x))
  print("image_x[0].shape: ", image_x[0].shape)
  print(image_x)
  break
#+END_SRC

#+RESULTS:

** Save Models
*** generator_g (normal -> watermark)
#+BEGIN_SRC python :results file
generator_g.save(model_dir / "generator_g")
model_dir / "generator_g"
#+END_SRC

#+RESULTS:
[[file:/Users/antoniomendes/Desktop/uva_data_science/semester_01/block_02/AML/Kaggle_Project/models/generator_g]]

*** discriminator_x (watermark)
#+BEGIN_SRC python :results file
discriminator_x.save(model_dir / "discriminator_x")
model_dir / "discriminator_x"
#+END_SRC

#+RESULTS:
[[file:/Users/antoniomendes/Desktop/uva_data_science/semester_01/block_02/AML/Kaggle_Project/models/discriminator_x]]

*** generator_f (watermark -> normal)
#+BEGIN_SRC python :results file
generator_f.save(model_dir / "generator_f")
model_dir / "generator_f"
#+END_SRC

#+RESULTS:
[[file:/Users/antoniomendes/Desktop/uva_data_science/semester_01/block_02/AML/Kaggle_Project/models/generator_f]]

*** discriminator_y 
#+BEGIN_SRC python :results file
discriminator_y.save(model_dir / "discriminator_y")
model_dir / "discriminator_y"
#+END_SRC

#+RESULTS:
[[file:/Users/antoniomendes/Desktop/uva_data_science/semester_01/block_02/AML/Kaggle_Project/models/discriminator_y]]

