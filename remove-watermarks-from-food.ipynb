{"cells":[{"metadata":{},"cell_type":"markdown","source":"# Table of Contents\n\n* [Introduction](#introduction)\n* [Imports](#imports)\n    - [Standard](#standard)\n    - [Import OS and Get/Make Directories](#import-os)\n    - [Tensorflow & Keras](#tensorflow)\n    - [Other Tools](#other-tools)\n* [Data](#data)\n    - [Convert Images to Tensors](#convert-images)\n* [Translate Images](#translate-images)\n* [Save Translation](#save-translation)\n* [Test Set](#test-set)\n    - [Data](#test-data)\n    - [Translate Images](#test-translate-images)\n    - [Save Translation](#test-save-translation)"},{"metadata":{},"cell_type":"markdown","source":"# Introduction <a id=\"introduction\"></a>\n\nAfter the cycleGAN has been trained in train_watermark_removal.ipynb, then next step is to apply the cycleGAN to the train and test sets of food images and remove watermarks. As mentioned before, only generator G_n that translates watermarked images to unwatermarked images, is necessary for this. "},{"metadata":{},"cell_type":"markdown","source":"# Imports <a id=\"imports\"></a>"},{"metadata":{},"cell_type":"markdown","source":"## Standard <a id=\"standard\"></a>"},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"import numpy as np\nimport pandas as pd","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Import OS and Get/Make Directories <a id=\"import-os\"></a>"},{"metadata":{"trusted":true},"cell_type":"code","source":"import os \nfrom pathlib import Path\ncwd = os.path.abspath(os.getcwd())\ncwd","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data_dir = Path(\"/\".join(cwd.split(\"/\"))) / \"data\"\n\ndata_dir","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_dir = data_dir / \"train_set\"\n\ntrain_dir","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_dir = data_dir / \"test_set\"\n\ntest_dir","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model_dir = Path(cwd) / \"models\"\n\nmodel_dir","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Tensorflow & Keras <a id=\"tensorflow\"></a>"},{"metadata":{"trusted":true},"cell_type":"code","source":"import tensorflow as tf\nimport tensorflow_datasets as tfds\n\nfrom tensorflow.keras import layers\nfrom keras.models import Sequential, Model, load_model\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Other Tools <a id=\"other-tools\"></a>"},{"metadata":{"trusted":true},"cell_type":"code","source":"from tqdm import tqdm\nfrom PIL import Image","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Data <a id=\"data\"></a>"},{"metadata":{},"cell_type":"markdown","source":"## Convert Images to Tensors <a id=\"convert-images\"></a>"},{"metadata":{"trusted":true},"cell_type":"code","source":"original_images = os.listdir(train_dir)\nif \".DS_Store\" in original_images:\n  original_images.remove(\".DS_Store\")\n\ntensor_images = []\nfor img_name in tqdm(original_images):\n  img_rgb = cv2.cvtColor(cv2.imread(filename=str(train_dir / img_name)), cv2.COLOR_BGR2RGB)\n  tensor_images.append(tf.convert_to_tensor(img_rgb, dtype=tf.float32))\n\n\ntensor_images = np.asarray(tensor_images)\ntensor_images.shape","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Normalise Tensors <a id=\"normalise-tensors\"></a>"},{"metadata":{"trusted":true},"cell_type":"code","source":"def normalize(image):\n  image = tf.cast(image, tf.float32)\n  image = (image / 127.5) - 1\n  return image","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"normalised_tensors = []\nfor tensor_img in tqdm(tensor_images):\n  normalised_tensors.append(normalize(tensor_img))\n\nnormalised_tensors = np.asarray(normalised_tensors)\nnormalised_tensors.shape","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Translate Images <a id=\"translate-images\"></a>"},{"metadata":{"trusted":true},"cell_type":"code","source":"remove_watermarks = tf.keras.models.load_model(model_dir / \"generator_n\")\n\nremove_watermarks.summary()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def crop_image_height(image):\n  if image.shape[1] > 256:\n    max_height = image.shape[1]\n    max_slice = max_height - 257\n    start_slice = np.random.randint(0, max_slice) if max_slice > 0 else 0\n    end_slice = start_slice + 256\n    return image[:,start_slice:end_slice,:]\n  else: \n    return image","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def crop_image_width(image):\n  if image.shape[0] > 256:\n    max_width = image.shape[0]\n    max_slice = max_width - 257\n    start_slice = np.random.randint(0, max_slice) if max_slice > 0 else 0\n    end_slice = start_slice + 256\n    return image[start_slice:end_slice,:,:]\n  else: \n    return image","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"mark_removed_tensors = []\n\nfor t_img in tqdm(normalised_tensors):\n    cropped_img = crop_image_height(t_img)\n    cropped_img = crop_image_width(cropped_img)\n    mark_removed_tensors.append(remove_watermarks.predict(cropped_img[np.newaxis,:]))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Save Translation <a id=\"save-translation\"></a>"},{"metadata":{},"cell_type":"markdown","source":"The code block below is implemented from this [StackOverflow answer](https://stackoverflow.com/questions/57338091/how-to-save-tensor-as-a-image)."},{"metadata":{"trusted":true},"cell_type":"code","source":"filenames = os.listdir(train_dir)\nif \".DS_Store\" in filenames:\n  filenames.remove(\".DS_Store\")\n\nno_of_files = len(filenames)\nno_of_files","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_mrk_removed_dir = data_dir / \"train_set_watermark_removed\"\nif train_mrk_removed_dir.exists() == False:\n  os.mkdir(train_mrk_removed_dir)\n\ndata_dir","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The code block below is implemented from this [StackOverflow answer](https://stackoverflow.com/questions/57338091/how-to-save-tensor-as-a-image)."},{"metadata":{"trusted":true},"cell_type":"code","source":"with tf.Session() as sess:\n    init = tf.group(tf.global_variables_initializer(),tf.local_variables_initializer())\n    sess.run(init)\n    tf.train.start_queue_runners()\n    for i in tqdm(range(no_of_files)):\n        img_tnsr = mark_removed_tensors[i]\n        img = sess.run(img_tnsr)\n        img = Image.fromarray(img)\n        img.save(test_mrk_removed_dir / filenames[i])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Test Set <a id=\"test-set\"></a>"},{"metadata":{},"cell_type":"markdown","source":"## Data <a id=\"test-data\"></a>"},{"metadata":{"trusted":true},"cell_type":"code","source":"original_images = os.listdir(train_dir)\nif \".DS_Store\" in original_images:\n  original_images.remove(\".DS_Store\")\n\ntensor_images = []\nfor img_name in tqdm(original_images):\n  img_rgb = cv2.cvtColor(cv2.imread(filename=str(train_dir / img_name)), cv2.COLOR_BGR2RGB)\n  tensor_images.append(tf.convert_to_tensor(img_rgb, dtype=tf.float32))\n\n\ntensor_images = np.asarray(tensor_images)\ntensor_images.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"normalised_tensors = []\nfor tensor_img in tqdm(tensor_images):\n  normalised_tensors.append(normalize(tensor_img))\n\nnormalised_tensors = np.asarray(normalised_tensors)\nnormalised_tensors.shape","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Translate Images <a id=\"test-translate-images\"></a>"},{"metadata":{"trusted":true},"cell_type":"code","source":"remove_watermarks = tf.keras.models.load_model(model_dir / \"generator_f\")\n\nremove_watermarks.summary()","execution_count":1,"outputs":[{"output_type":"error","ename":"NameError","evalue":"name 'tf' is not defined","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-1-f7eb3dcb4d54>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mremove_watermarks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_dir\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;34m\"generator_f\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;31mNameError\u001b[0m: name 'tf' is not defined"]}]},{"metadata":{"trusted":true},"cell_type":"code","source":"mark_removed_tensors = []\n\nfor t_img in tqdm(normalised_tensors):\n  cropped_img = crop_image_height(t_img)\n  cropped_img = crop_image_width(cropped_img)\n  mark_removed_tensors.append(remove_watermarks.predict(cropped_img[np.newaxis,:]))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Save Translation <a id=\"test-save-translation\"></a>"},{"metadata":{"trusted":true},"cell_type":"code","source":"filenames = os.listdir(test_dir)\nif \".DS_Store\" in filenames:\n  filenames.remove(\".DS_Store\")\nno_of_files = len(filenames)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_mrk_removed_dir = data_dir / \"test_set_watermark_removed\"\nif test_mrk_removed_dir.exists() == False:\n  os.mkdir(test_mrk_removed_dir)\n\ntest_mrk_removed_dir","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"with tf.Session() as sess:\n    init = tf.group(tf.global_variables_initializer(),tf.local_variables_initializer())\n    sess.run(init)\n    tf.train.start_queue_runners()\n    for i in tqdm(range(no_of_files)):\n        img_tnsr = mark_removed_tensors[i]\n        img = sess.run(img_tnsr)\n        img = Image.fromarray(img)\n        img.save(test_mrk_removed_dir / filenames[i])","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.7.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":4}